import torch
import torch.nn.functional as F
def denormalize(data, mean, std):
    """
    对归一化数据进行反归一化。
    
    Args:
        data: 归一化的数据，可以是 list 或 torch.Tensor，形状如 [B, T, D] 或任意嵌套列表。
        mean: 均值列表，长度等于特征维度 D。
        std: 标准差列表，长度等于特征维度 D。
    
    Returns:
        反归一化后的数据（list 或 Tensor，与输入类型一致）。
    """
    # 转为 Tensor 便于统一计算
    if not isinstance(data, torch.Tensor):
        tensor_input = False
        data_tensor = torch.tensor(data, dtype=torch.float32)
    else:
        tensor_input = True
        data_tensor = data.clone().float()

    mean_tensor = torch.tensor(mean, dtype=torch.float32)
    std_tensor = torch.tensor(std, dtype=torch.float32)

    # 广播：假设最后一维是特征维
    denorm_data = data_tensor * std_tensor + mean_tensor

    if tensor_input:
        return denorm_data
    else:
        return denorm_data.tolist()
    
ground_truth = [
      [
        -0.9140625,
        -0.25,
        -0.0859375,
        -0.0137939453125,
        1.4453125,
        2.75,
        1.0
      ],
      [
        -0.9609375,
        -0.271484375,
        -0.1337890625,
        -0.0137939453125,
        1.4296875,
        2.96875,
        1.0
      ],
      [
        -0.9921875,
        -0.314453125,
        -0.2001953125,
        0.150390625,
        1.28125,
        3.15625,
        1.0
      ],
      [
        -1.03125,
        -0.271484375,
        -0.248046875,
        0.287109375,
        0.9765625,
        3.34375,
        1.0
      ],
      [
        -0.921875,
        -0.2294921875,
        -0.296875,
        0.50390625,
        0.7734375,
        3.59375,
        1.0
      ]
    ]

mean = [
    0.06278156570450202,
    0.08684081017968912,
    -0.09037305936952836,
    0.0005407430783705139,
    0.0056433796450358715,
    -0.005229098518603562,
    -0.04964072167678376
]
std = [
    0.33552371813523185,
    0.37844699137610033,
    0.4447286014970994,
    0.03924354055831819,
    0.06339296374013795,
    0.07797027468104202,
    0.9987671387144731
]

actions =[
      [
        -0.03874513506889343,
        0.2678874135017395,
        -0.47905486822128296,
        0.04001692309975624,
        0.012246815487742424,
        0.021826526150107384,
        0.7598356008529663
      ],
      [
        -0.07012469321489334,
        0.21496164798736572,
        -0.46882155537605286,
        0.03548411652445793,
        0.051481325179338455,
        0.03535495698451996,
        0.5058391094207764
      ],
      [
        -0.015581801533699036,
        0.25039947032928467,
        -0.450260728597641,
        0.039614640176296234,
        0.027977529913187027,
        0.03480340540409088,
        0.5621570348739624
      ],
      [
        -0.06368453055620193,
        0.2665345072746277,
        -0.5094987750053406,
        0.03452501818537712,
        0.018361937254667282,
        0.029459273442626,
        0.5272026658058167
      ],
      [
        -0.17251518368721008,
        0.23338499665260315,
        -0.4942110776901245,
        0.047631438821554184,
        -0.009463351219892502,
        0.036602869629859924,
        0.7719086408615112
      ]
]
    
denorm_gt = denormalize(ground_truth, mean, std)

# 打印第一帧第一个点的反归一化结果（可选保留两位小数）
for i in range(len(denorm_gt)):
    print([round(x, 4) for x in actions[i]])
    

actions = torch.tensor(actions)
denorm_gt = torch.tensor(denorm_gt)
mse_loss = F.mse_loss(actions, denorm_gt)

print(f"MSE Loss between denormalized actions and ground truth: {mse_loss.item()}")